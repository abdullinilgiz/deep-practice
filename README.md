# Глубокое обучение на практике
## Что было сделано?
### Задача
Создать прототип помощника для водителей, который будет оповещать их о дорожных знаках.
### Данные 
Не предоставлены данные для обучения модели. Соответственно их необходимо было найти. Был выбран [датасет](https://www.cvl.isy.liu.se/en/research/datasets/traffic-signs-dataset/). Далее возникла проблема, YOLO требует специальной аннотации, которая не совпадала с аннотацией нашего датасета. Поэтому было принято решение, написать скрипт, который трансформирует одну аннотацию в другую (`parsing.py`). Таким образом получилось собрать 4т. размеченных изображений, на 2.8т из которых был хотя бы 1 знак.

### Модель
Была выбрана модель YOLO т.к. задача декомпозируется на детекцию и классификацию, а это как раз проблема которую решает YOLO.
Было выбрано две модели для тестирования YOLOv5s, YOLOv8s.

![yolo_comparison](https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/yolo-comparison-plots.png)

Из графиков выидно, при примерно одинаковый размерах, и скорости работы, YOLOv8s демонстрирует более высокие показатели mAP50-95. Для проверки данного утверждения мы решили обучить обе модели на одинаковом датасете. Результаты обучения вы можете видеть в разделе с метриками.

### Подбор гиперпараметров
Фреймы видео представляют из себя изображения, дорожные знаки на которых могут занимать малую часть изображения. В связи с чем главным гиперпарамтером является размер входного изображения. В первую очеред данный параметр `imgsz` был выбран равным `320`. При таких размерах изображения знаки на видео преобразуются в еще маньшее количество пикселей, как результат, детекция была хаотичной, модель часто ошибалась в классификации и даже детектировала с высокой уверенностью знаки, которых нет. Было решено увеличить размер входного изображения до `480`, это не привело к увеличению качества результата. Следующим шагом был выбран `imgsz=960`, что сильно увеличило качество детекции. К сожалению такой большой размер входного изображения требует большого количества ресурсов, поэтому пришлось уменьшиать `batch` (размер пакета) до 4, что сильно замедлило скорость обучения. Например, модель yolo8s обучалась 4 часа, и за это время успело пройти 100 эпох.

### Метрики
`mAP50` и `mAP50-95` - это метрики, используемые для оценки качества работы моделей объектного обнаружения (`object detection`) в компьютерном зрении. Обе метрики связаны с метрикой средней точности обнаружения (mean Average Precision, mAP), но с различными параметрами для расчета.

`IoU` (Intersection over Union) - это мера, используемая для измерения степени перекрытия между предсказанным объектом и истинным объектом в данных обнаружения объектов.

mAP50 (mean Average Precision at 50 IoU):
измеряет среднюю точность обнаружения при пороге IoU в 50%. Таким образом, предсказанный объект считается верно обнаруженным, если IoU больше 0.5.

mAP50-95 (mean Average Precision from 50 to 95 IoU):
эта метрика учитывает среднюю точность обнаружения в диапазоне порогов IoU от 50% до 95% с шагом 5%. Таким образом, она более полно оценивает производительность модели в различных уровнях перекрытия объектов.

Графики обучения и валидации YOLOv8s:
![results_v8](data/results_v8.png "Графики обучения и валидации YOLOv8s")

Графики обучения и валидации YOLOv5s:
![results_v5](data/results_v5.png "Графики обучения и валидации YOLOv5s")

Видим, что обе модели не переобучились. Оценим матрицу ошибок на валидационной части датасета. Модели демонстрируют примерно одинаковый результат. `YOLOv8` чуть более лучший результат.

![confusion_v8](data/confusion_matrix_v8.png "Confusion matrix YOLOv8s")

![confusion_v5](data/confusion_matrix_v5.png "Confusion matrix YOLOv5s")

Также проводилась человечкская оценка качества работы модели на видео с видеорегистратора в режиме раельного времени. Для этого использовались `yolo_test.ipynb`, `yolo8_test.ipynb`. 

Видео с работой моделей вы можете найти по ссылкам:

[YOLOv5s](https://youtu.be/MBlS5E19TxM)

[YOLOv8s](https://youtu.be/X7MT9XkDZU0)

Мы видим, что детекция 5-ой модели гараздо более хаотичная. Модель детектирует несуществующие знаки, модель неправльно классифицирует существующие. Из видео с 8-ой моделью видно, что она справляется с задачей гораздо лучше.

По совокупности метрик, была выбрана последняя модель YOLO.


### Результат
[Видео](https://youtu.be/jbBXwSy7uUI) для быстрой оценки полученного результата. Наша модель научилась успешно распозновать популярные знаки на дороге. На видео мы можем увидеть: GIVE_WAY - уступи дорогу, PEDESTRIANS_CROSSING - пешеходный переход, или осторожно пешеходы, PRIORITY_ROAD - главная дорога.

 Модель обучалась на этих изображениях. Лучший из полученных результатов вы можете найти в `best/last.pt`. Чтобы оценить ее работоспособность, вы можете использовать консольную команду:
 ```
python3 notebooks/show.py best/last.pt data/day_alot.mp4
 ```
 Обратите, внимание файл day_alot.mp4 вы можете взять из наших данных по ссылке ниже (категория "обучение на вашем датасете")
 
 Также для проверки работы вы можете воспользоваться ноутбуками `yolo_test.ipynb` и `frame_test.ipynb`.
 Проверить качесто разметки можно с помощью файла `boundbox.py`.

## Установка
### Оргинизуем виртуальное окружение проекта
В корневой папке вашего репозитория выполните:
```
python3 -m venv venv
. venv/bin/activate
```

### Клонируем репозиторий с YOLO
В корневой папке вашего репозитория выполните:
```
git clone https://github.com/ultralytics/yolov5
cd yolo5
pip install -r requirements.txt
```
Далее нужно установить необходимые библиотеки для остальных файлов репозитория. Выполняем следущую команду из корня данного репозитория:
```
pip install -r requirements.txt
```

### Обучение на вашем датасете
Наши данные вы можете скачать по [ссылке](https://disk.yandex.ru/d/yLcFb1zlbjQQiw). Данный архив нужно распоковать в корневую директорию данного репозитория.

Для обучения на собственном датасете необходимо создать файл dataset.yaml. Этот файл должен отвечать определенным требованиям, которые вы можете увидеть по [ссылке](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#11-create-datasetyaml). Я расположил данный файл в `notebooks/`.
Перед запуском обучения необходимо загрузить веса для дообучения.
```
python3
>>> import torch
>>> torch.hub.load('ultralytics/yolov5', 'yolov5s')
```
Чтобы запустить процесс обучения необходимо выполнить следующую консольную команду.
```
python3 yolov5/train.py --img 960 --batch 4 --epochs 20 --data notebooks/dataset.yaml --weights yolov5s.pt
```
Таким же образом можно дообучить вашу модель, просто поменяв путь до файла, например:
```
python3 yolov5/train.py --img 960 --batch 4 --epochs 20 --data notebooks/dataset.yaml --weights /yolov5/runs/train/exp/weights/last.pt
```


